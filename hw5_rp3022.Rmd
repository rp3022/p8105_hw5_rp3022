---
title: "homework 5"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


```{r load_libraries}
library(tidyverse)
```

## problem 2

Importing the raw homicides dataset:
```{r, message=FALSE}
library (readr)

urlfile="https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_raw <-read_csv(url(urlfile)) %>% 
  janitor::clean_names()
```

#### Raw dataset description:
The dataset contains data of criminal homicides over the past decade in 50 American cities. 

* The total number of observations  are **`r nrow(homicide_raw)`** and the total number of variables are **`r ncol(homicide_raw)`**
* It includes variables **`r colnames(homicide_raw)`**. 


```{r summarizing homicides}
homicide = homicide_raw %>%
unite('city_state',"city":"state", remove = FALSE)%>%
  select(-city,-state)%>%
   mutate (homi_type = case_when (disposition == "Closed without arrest" ~ "unsolved", 
                                  disposition == "Open/No arrest" ~ "unsolved", 
                                  disposition == "Closed by arrest" ~ "solved" )) %>%
  group_by(city_state) %>%
  filter (city_state != "Tulsa_AL") %>%
  count(homi_type) %>%
  spread(key = homi_type, value = n)%>%
  mutate (total = solved + unsolved) %>%
  select (-solved) 
  
```

#### Filtering and Estimating Homicide proportion for Baltimore:
```{r Baltimore homicides}
baltimore = homicide %>%
  filter(city_state == "Baltimore_MD")
```

```{r Baltimore proportion}
balt_prop = 
  prop.test(baltimore$unsolved, baltimore$total)%>%
  broom::tidy() %>%
  select (estimate, conf.low, conf.high)

  knitr::kable(balt_prop)
```

#### Estimating Homicide proportion for each city 
```{r proportions for each cities}
city_prop = homicide %>%
  mutate(city_prop = list(broom::tidy(prop.test(unsolved, total, conf.level=0.95)))) %>%
  unnest(city_prop)%>%
  select (city_state, estimate, conf.low, conf.high)%>%
  ungroup()

  knitr::kable(city_prop)
 
```

#### Plotting for estimates and 95% CI for each city
```{r plotting proportions}
plot_city = city_prop %>%
  mutate (city_state = reorder (city_state, estimate)) %>%
  ggplot(aes (x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 60, hjust = 1)) + 
  labs (title = "Plot for proportion estimate and 95% CI for each city",
        x = "City and State",
        y = "Proportion estimate with 95% CI")
  
plot_city
```

### problem 3
Setting up a simulation

```{r}
sim_in = function(n = 30, mu = 0, sigma = 5) {
    x = rnorm(n, mean = mu, sd = sigma)
    test = t.test (x, mu = 0, conf.level = 0.95) %>%
      broom::tidy() %>%
    select(estimate, p.value)
    
    test
}


```
generating 5000 datasets and repeating simulations for all levels of mu

```{r}
sim_5000 = vector("list", 5000)
for(i in 1:5000) {
  sim_5000 [[i]]=sim_in()
}

sim_5000 = sim_5000 %>% 
  bind_rows()
  
```
```{r}
sim_all = function(set){
  mu_all = vector("list", 5000)
  for(i in 1:5000){
    mu_all[[i]]=sim_in(mu=set)
  }
  power = mu_all %>% 
    bind_rows()
  
  power
  }

```

```{r}
sim_any = 
  tibble(
    mu_val = c(0,1,2,3,4,5,6),
    estimates = map(mu_val, sim_all)
  ) %>% 
  unnest(estimates) %>% 
  mutate(
    reject_if = ifelse(p.value< 0.05, TRUE, FALSE)
  )
```

#### Creating plots 

```{r plot for power and mu}
power_plot = sim_any %>%
  group_by(mu_val) %>%
  summarise(power = sum(reject_if)/5000) %>%
  ggplot(aes(x = mu_val, y = power)) +
  geom_point (aes(color = mu_val)) +
  geom_line() + 
  labs (title = " Power vs True value of mu",
        x = "True value of Mu",
        y = "Power")
  power_plot
```

From the graph it can be observed that as the true value of μ increases, the power of the test also increases. We can conclude that the effect size increases, the power of the test to reject the null also increases.

```{r average vs true}
reject_avg = sim_any %>%
  group_by(mu_val) %>%
  filter (reject_if == TRUE) %>%
  summarise (mean_reject = mean(estimate))

all_avg = sim_any %>%
  group_by(mu_val) %>%
  summarise (mean_all = mean(estimate))

avg_combined = full_join(reject_avg, all_avg, by = "mu_val") %>%
  pivot_longer(
    mean_reject:mean_all,
    names_to = "samples",
    values_to = "avg_estimates"
  )

all_plot = all_avg %>%
  ggplot (aes(x= mu_val, y= mean_all)) +
  geom_point (alpha = 0.5) + 
  geom_line () +
labs (title = "True vs Average estimate of μ^ for all sample",
        x = "True value of μ",
        y = "Average estimate of μ^")
all_plot

reject_plot = reject_avg %>%
  ggplot (aes(x= mu_val, y= mean_reject)) +
  geom_point (alpha = 0.5) + 
  geom_line () +
labs (title = "True value vs Average estimate of μ^ when null was rejected",
        x = "True value of μ",
        y = "Average estimate of μ^ for Null-rejected")
reject_plot

overlay_plot = avg_combined %>%
  ggplot (aes(x= mu_val, y= avg_estimates, group = samples)) +
  geom_point (aes(color = samples), alpha = 0.5) + 
  geom_line (aes(color = samples)) +
labs (title = "Overlay Plot for true value of μ vs Average estimate of μ^ in all sample and rejected sample",
        x = "True value of μ",
        y = "Average estimate of μ^ for Null-rejected")
overlay_plot
```




